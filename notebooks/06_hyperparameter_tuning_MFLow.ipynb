{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89cf7200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.5\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260096cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/Regression_ML_EndtoEnd/.venv/bin/python\n",
      "3.0.5\n",
      "/workspaces/Regression_ML_EndtoEnd/.venv/lib/python3.11/site-packages/xgboost/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys, xgboost as xgb\n",
    "print(sys.executable)        # should point to .../.venv/bin/python\n",
    "print(xgb.__version__)       # should print 3.0.4\n",
    "print(xgb.__file__)          # should live under .../.venv/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "478bf394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 1. Imports\n",
    "# ==============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0bc804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (576815, 39)\n",
      "Eval shape: (148448, 39)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 2. Load processed datasets\n",
    "# ==============================================\n",
    "train_df = pd.read_csv(\"/workspaces/Regression_ML_EndtoEnd/data/processed/feature_engineered_train.csv\")\n",
    "eval_df  = pd.read_csv(\"/workspaces/Regression_ML_EndtoEnd/data/processed/feature_engineered_eval.csv\")\n",
    "\n",
    "\n",
    "# Define target + features\n",
    "target = \"price\"\n",
    "X_train, y_train = train_df.drop(columns=[target]), train_df[target]\n",
    "X_eval, y_eval   = eval_df.drop(columns=[target]), eval_df[target]\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Eval shape:\", X_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fadb78cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# 3. Define Optuna objective function with MLflow\n",
    "# ==============================================\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"tree_method\": \"hist\",\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_eval)\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_eval, y_pred)))\n",
    "        mae = float(mean_absolute_error(y_eval, y_pred))\n",
    "        r2 = float(r2_score(y_eval, y_pred))\n",
    "\n",
    "        # Log hyperparameters + metrics\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed4b5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/02 12:33:30 INFO mlflow.tracking.fluent: Experiment with name 'xgboost_optuna_housing' does not exist. Creating a new experiment.\n",
      "[I 2025-10-02 12:33:30,210] A new study created in memory with name: no-name-dfd2ce1d-1a3d-49eb-aa6c-82231af3a70b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-02 12:34:17,624] Trial 0 finished with value: 71415.53305533597 and parameters: {'n_estimators': 305, 'max_depth': 10, 'learning_rate': 0.03407501606727369, 'subsample': 0.8602877885190545, 'colsample_bytree': 0.5892187410236365, 'min_child_weight': 5, 'gamma': 1.4558180216602856, 'reg_alpha': 2.538093154267891, 'reg_lambda': 1.3612045179653684e-08}. Best is trial 0 with value: 71415.53305533597.\n",
      "[I 2025-10-02 12:35:41,570] Trial 1 finished with value: 75106.61915531826 and parameters: {'n_estimators': 788, 'max_depth': 9, 'learning_rate': 0.1915756271874383, 'subsample': 0.7601530688482399, 'colsample_bytree': 0.7025958286567734, 'min_child_weight': 5, 'gamma': 2.7229294239089237, 'reg_alpha': 2.6943146061903858, 'reg_lambda': 2.3265713889444713e-08}. Best is trial 0 with value: 71415.53305533597.\n",
      "[I 2025-10-02 12:37:22,878] Trial 2 finished with value: 72601.35246149 and parameters: {'n_estimators': 934, 'max_depth': 9, 'learning_rate': 0.06882219424675885, 'subsample': 0.733269210104079, 'colsample_bytree': 0.6922347191929683, 'min_child_weight': 4, 'gamma': 0.01562739517358691, 'reg_alpha': 8.670813278574882e-08, 'reg_lambda': 0.0009602387717179566}. Best is trial 0 with value: 71415.53305533597.\n",
      "[I 2025-10-02 12:38:10,263] Trial 3 finished with value: 70078.56336916739 and parameters: {'n_estimators': 355, 'max_depth': 10, 'learning_rate': 0.06778843392150417, 'subsample': 0.6234621763303874, 'colsample_bytree': 0.566849806145, 'min_child_weight': 9, 'gamma': 2.5857868472193375, 'reg_alpha': 0.004084666404438511, 'reg_lambda': 0.010542453872104411}. Best is trial 3 with value: 70078.56336916739.\n",
      "[I 2025-10-02 12:39:01,460] Trial 4 finished with value: 75645.07981822375 and parameters: {'n_estimators': 988, 'max_depth': 5, 'learning_rate': 0.014961807620259717, 'subsample': 0.8024203278706332, 'colsample_bytree': 0.7032662140163275, 'min_child_weight': 9, 'gamma': 3.030574751490356, 'reg_alpha': 0.018408925647760633, 'reg_lambda': 6.9708237124302824e-06}. Best is trial 3 with value: 70078.56336916739.\n",
      "[I 2025-10-02 12:40:43,174] Trial 5 finished with value: 73362.57392360986 and parameters: {'n_estimators': 946, 'max_depth': 9, 'learning_rate': 0.11153307266650575, 'subsample': 0.6869896313952842, 'colsample_bytree': 0.81206482879531, 'min_child_weight': 5, 'gamma': 3.7664361502165624, 'reg_alpha': 2.5806838576609018e-05, 'reg_lambda': 1.7076246172046117e-05}. Best is trial 3 with value: 70078.56336916739.\n",
      "[I 2025-10-02 12:41:53,395] Trial 6 finished with value: 74669.29484323761 and parameters: {'n_estimators': 761, 'max_depth': 8, 'learning_rate': 0.016033029465663113, 'subsample': 0.9475960880270515, 'colsample_bytree': 0.975050179267186, 'min_child_weight': 10, 'gamma': 1.2002873905283906, 'reg_alpha': 1.260355987030966e-08, 'reg_lambda': 8.683027757068431e-07}. Best is trial 3 with value: 70078.56336916739.\n",
      "[I 2025-10-02 12:42:41,306] Trial 7 finished with value: 70340.49790430139 and parameters: {'n_estimators': 993, 'max_depth': 5, 'learning_rate': 0.0426763431343474, 'subsample': 0.5532119412480504, 'colsample_bytree': 0.5080048807772063, 'min_child_weight': 7, 'gamma': 3.8237403865828012, 'reg_alpha': 0.11086914300192141, 'reg_lambda': 6.217311063398984e-07}. Best is trial 3 with value: 70078.56336916739.\n",
      "[I 2025-10-02 12:43:11,051] Trial 8 finished with value: 69207.75230932672 and parameters: {'n_estimators': 483, 'max_depth': 6, 'learning_rate': 0.06681540831190468, 'subsample': 0.949719208554441, 'colsample_bytree': 0.5041070772805798, 'min_child_weight': 7, 'gamma': 0.23574481400436054, 'reg_alpha': 3.1548471850647093e-06, 'reg_lambda': 0.016256976176657015}. Best is trial 8 with value: 69207.75230932672.\n",
      "[I 2025-10-02 12:43:30,985] Trial 9 finished with value: 74460.76688203173 and parameters: {'n_estimators': 507, 'max_depth': 3, 'learning_rate': 0.25172042007352335, 'subsample': 0.603317825419274, 'colsample_bytree': 0.8217805580402221, 'min_child_weight': 2, 'gamma': 4.390614685345021, 'reg_alpha': 2.3093460918543474, 'reg_lambda': 2.193345505273792}. Best is trial 8 with value: 69207.75230932672.\n",
      "[I 2025-10-02 12:44:02,990] Trial 10 finished with value: 78714.58219432102 and parameters: {'n_estimators': 512, 'max_depth': 6, 'learning_rate': 0.028385686481721295, 'subsample': 0.9672675032610949, 'colsample_bytree': 0.9778262799316978, 'min_child_weight': 7, 'gamma': 0.08551120790577155, 'reg_alpha': 3.6140720384575526e-06, 'reg_lambda': 0.4966581206481897}. Best is trial 8 with value: 69207.75230932672.\n",
      "[I 2025-10-02 12:44:23,854] Trial 11 finished with value: 69219.85948138009 and parameters: {'n_estimators': 281, 'max_depth': 7, 'learning_rate': 0.08458181559023319, 'subsample': 0.6469030085641665, 'colsample_bytree': 0.5019605512736561, 'min_child_weight': 8, 'gamma': 1.8201451907284967, 'reg_alpha': 0.0010230777421132264, 'reg_lambda': 0.012685448258832058}. Best is trial 8 with value: 69207.75230932672.\n",
      "[I 2025-10-02 12:44:40,378] Trial 12 finished with value: 69369.15477401626 and parameters: {'n_estimators': 218, 'max_depth': 7, 'learning_rate': 0.11076971652680383, 'subsample': 0.506329247490595, 'colsample_bytree': 0.5031451940453612, 'min_child_weight': 7, 'gamma': 1.3607899090827038, 'reg_alpha': 0.00012810418156715696, 'reg_lambda': 0.03932322287963173}. Best is trial 8 with value: 69207.75230932672.\n",
      "[I 2025-10-02 12:45:05,053] Trial 13 finished with value: 69516.6332128906 and parameters: {'n_estimators': 421, 'max_depth': 6, 'learning_rate': 0.11888784352799629, 'subsample': 0.8757539717127504, 'colsample_bytree': 0.6045418013774193, 'min_child_weight': 8, 'gamma': 0.7863502689078872, 'reg_alpha': 2.5781664266829166e-06, 'reg_lambda': 0.0014606412419557126}. Best is trial 8 with value: 69207.75230932672.\n",
      "[I 2025-10-02 12:45:31,639] Trial 14 finished with value: 73341.38936785978 and parameters: {'n_estimators': 597, 'max_depth': 4, 'learning_rate': 0.06012360658822507, 'subsample': 0.635961690709116, 'colsample_bytree': 0.6256909675650321, 'min_child_weight': 10, 'gamma': 1.959906489480486, 'reg_alpha': 0.0015638386687583064, 'reg_lambda': 0.09401699672240013}. Best is trial 8 with value: 69207.75230932672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 483, 'max_depth': 6, 'learning_rate': 0.06681540831190468, 'subsample': 0.949719208554441, 'colsample_bytree': 0.5041070772805798, 'min_child_weight': 7, 'gamma': 0.23574481400436054, 'reg_alpha': 3.1548471850647093e-06, 'reg_lambda': 0.016256976176657015}\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 4. Run Optuna study with MLflow\n",
    "# ==============================================\n",
    "# Force MLflow to always use the root project mlruns folder\n",
    "mlflow.set_tracking_uri(\"/workspaces/Regression_ML_EndtoEnd/mlruns\")\n",
    "mlflow.set_experiment(\"xgboost_optuna_housing\")\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Best params:\", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b8c223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final tuned model performance:\n",
      "MAE: 32971.394497178015\n",
      "RMSE: 69734.64355295326\n",
      "R²: 0.962419963126363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/Regression_ML_EndtoEnd/.venv/lib/python3.11/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:46:42] WARNING: /workspace/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/10/02 12:46:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 5. Train final model with best params and log to MLflow\n",
    "# ==============================================\n",
    "best_params = study.best_trial.params\n",
    "best_model = XGBRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_model.predict(X_eval)\n",
    "\n",
    "mae = mean_absolute_error(y_eval, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_eval, y_pred))\n",
    "r2 = r2_score(y_eval, y_pred)\n",
    "\n",
    "print(\"Final tuned model performance:\")\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²:\", r2)\n",
    "\n",
    "# Log final model\n",
    "with mlflow.start_run(run_name=\"best_xgboost_model\"):\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "    mlflow.xgboost.log_model(best_model, name=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1c1be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
